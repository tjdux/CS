## 저장 장치 계층 구조
- 저장 장치의 명제
  - CPU와 가까운 저장 장치는 빠르고, 멀리 있는 저장 장치는 느리다.
  - 속도가 빠른 저장 장치는 저장 용량이 작고, 가격이 비싸다.
  - ➡️ 빠른 속도의 저장 장치는 용량이 작고 비싸며, 반대로 대용량의 저장 장치는 속도가 느리다는 점에서 서로 trade-off 관계
- 저장 장치 계층 구조 (memory hierachy): 저장 장치들을 'CPU에 얼마나 가까운가'를 기준으로 계층화하여 표현한 구조
![image](https://github.com/user-attachments/assets/ddaec0b1-b3e0-4c4d-9c01-2737b8911888)
<br/>

## 캐시 메모리
- **캐시 메모리 (cache memory)**
  - CPU와 메모리 사이에 위치하고, 레지스터보다 용량이 크고 메모리보다 빠른 SRAM 기반의 저장 장치
  - CPU의 연산 속도와 메모리 접근 속도의 차이를 조금이나마 줄이기 위해 탄생 (CPU가 메모리에 접근하는 시간은 CPU 연산 속도보다 훨씬 느림)
  - 메모리에서 CPU가 사용할 일부 데이터를 미리 캐시 메모리로 가지고 와서 활용
- 코어와 가장 가까운 캐시 메모리를 L1 캐시, 그다음 가까운 메모리를 L2 캐시, 그다음 가까운 캐시 메모리를 L3 캐시
  - 메모리의 용량: L3 > L2 > L1
  - 속도: L1 > L2 > L3
  - 가격: L1 > L2 > L3
  - L1 캐시, L2 캐시: 코어마다 고유한 캐시 메모리로 할당
  - L3 캐시: 여러 코어가 공유하는 형태로 사용
  ![image](https://github.com/user-attachments/assets/d58a5646-2c64-4ba8-97d2-97cab57680c7)
  - ⚠️ 분리형 캐시
    - L1I 캐시: 명령어만을 저장
    - L1D 캐시: 데이터만을 저장
    ![image](https://github.com/user-attachments/assets/944e227e-6fac-43c1-9169-8c05b0422462)
- 캐시 메모리를 반영한 저장 장치 계층 구조
![image](https://github.com/user-attachments/assets/da845644-4b75-482f-849d-6d91a57b8de4)
<br/>

## 참조 지역성 원리
- **캐시 메모리는 CPU가 사용할 법한 대상을 예측하여 저장**
### 캐시 적중률
- 캐시 적중률 (cache hit ratio) = 캐시 히트 횟수 / (캐시 히트 횟수 + 캐시 미스 횟수))
  - 캐시 히트 (cache hit): 자주 사용될 것으로 예측한 데이터가 실제로 들어맞아 캐시 메모리 내 데이터가 CPU에서 활용될 경우
  - 캐시 미스 (cache miss): 예측이 틀려 메모리에서 필요한 데이터를 직접 가져와야 하는 경우
- 캐시 미스가 자주 발생할 경우 성능 떨어짐
- 캐시 메모리의 이점을 제대로 활용하기 위해서는 CPU가 자주 사용할 법한 데이터를 제대로 예측하여 캐시 적중률을 높여야 함
### 참조 지역성 원리
- 캐시 메모리가 메모리로부터 가져올 데이터를 결정하는 원칙
- CPU가 메모리에 접근할 때의 주된 경향을 바탕으로 만들어진 원리
- 1️⃣ 시간 지역성 (temporal locality)
  - CPU는 최근에 접근했던 메모리 공간에 다시 접근하려는 경향이 있음
  - e.g. 변수에 저장된 값은 일반적으로 한 번만 사용되지 않고 프로그램이 실행되는 동안 여러 번 사용됨
- 2️⃣ 공간 지역성 (spatial locality)
  - CPU는 접근한 메모리 공간 근처를 접근하려는 경향이 있음
  - CPU가 실행하려는 프로그램은 보통 관련 데이터들끼리 한데 모여있음
  - 하나의 프로그램 내에서도 관련 있는 데이터들은 모여서 저장 
